{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WxzBr-8UUqTt"
      },
      "outputs": [],
      "source": [
        "# --- 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ---\n",
        "!pip install -q -U transformers peft accelerate trl datasets huggingface_hub fastapi \"uvicorn[standard]\" pyngrok bitsandbytes \"pandas==2.2.2\" \"psycopg2-binary\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba6nuss7UyIt",
        "outputId": "4dd0396b-5c13-4930-e735-bf4f8d151ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ğŸ“‚ íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤ ---\n",
            "'gemma-fashion-dpo-final-v3.zip'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
            "'styles.csv'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# --- 2. íŒŒì¼ ì—…ë¡œë“œ ë° ë¡œê·¸ì¸ ---\n",
        "from google.colab import files\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "print(\"--- ğŸ“‚ íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤ ---\")\n",
        "files_to_upload = ['gemma-fashion-dpo-final-v3.zip', 'styles.csv']\n",
        "for filename in files_to_upload:\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"\\n'{filename}'ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
        "        files.upload()\n",
        "    else:\n",
        "        print(f\"'{filename}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSLsuKKYU2BL",
        "outputId": "ccd3397b-1055-4ccf-95be-c405acdf873a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ëª¨ë¸ í´ë” ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤...\n",
            "âœ… 'adapter_config.json'ì˜ ì •í™•í•œ ê²½ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: /content/content/gemma-fashion-dpo-final-v3\n"
          ]
        }
      ],
      "source": [
        "# --- 3. ëª¨ë¸ í´ë” ì••ì¶• í•´ì œ ë° 'ìë™ ê²½ë¡œ íƒì§€' ---\n",
        "print(\"\\nëª¨ë¸ í´ë” ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤...\")\n",
        "!unzip -q -o gemma-fashion-dpo-final-v3.zip -d /content/\n",
        "\n",
        "ADAPTER_PATH_FOUND = \"\"\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if 'adapter_config.json' in files:\n",
        "        ADAPTER_PATH_FOUND = root\n",
        "        break\n",
        "\n",
        "if not ADAPTER_PATH_FOUND:\n",
        "    raise FileNotFoundError(\"ì••ì¶• í•´ì œ í›„ 'adapter_config.json'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Zip íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "print(f\"âœ… 'adapter_config.json'ì˜ ì •í™•í•œ ê²½ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {ADAPTER_PATH_FOUND}\")\n",
        "# â— ì°¾ì€ ê²½ë¡œë¥¼ í™˜ê²½ ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
        "os.environ['ADAPTER_PATH'] = ADAPTER_PATH_FOUND\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ie42SukU5ew",
        "outputId": "1fa47640-5fb5-4ca7-c22b-43093f68bbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting serve_final.py\n"
          ]
        }
      ],
      "source": [
        "#@title 3. API ì„œë²„ ì½”ë“œ ì‘ì„± (serve_final.py) - ìµœì¢… ìƒì„¸ ì˜¤ë¥˜ ì‘ë‹µ\n",
        "\n",
        "%%writefile serve_final.py\n",
        "\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "import time\n",
        "import random\n",
        "from fastapi import FastAPI, Request\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.exceptions import RequestValidationError # â˜… ìƒì„¸ ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Dict, Any\n",
        "import uvicorn\n",
        "import logging\n",
        "\n",
        "# --- ê¸°ë³¸ ì„¤ì • ---\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "app = FastAPI()\n",
        "\n",
        "# --- â˜… NEW: ìƒì„¸í•œ ìœ íš¨ì„± ê²€ì‚¬ ì˜¤ë¥˜ ì‘ë‹µì„ ìœ„í•œ ì˜ˆì™¸ ì²˜ë¦¬ê¸° ---\n",
        "@app.exception_handler(RequestValidationError)\n",
        "async def validation_exception_handler(request: Request, exc: RequestValidationError):\n",
        "    \"\"\"\n",
        "    422 ì—ëŸ¬ ë°œìƒ ì‹œ, FastAPIì˜ ê¸°ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ëŒ€ì‹ \n",
        "    ì–´ë–¤ í•„ë“œê°€ ì™œ ì˜ëª»ë˜ì—ˆëŠ”ì§€ ìƒì„¸í•œ ì •ë³´ë¥¼ ë‹´ì•„ JSONìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    error_details = []\n",
        "    for error in exc.errors():\n",
        "        error_details.append({\n",
        "            \"loc\": error['loc'],\n",
        "            \"msg\": error['msg'],\n",
        "            \"type\": error['type']\n",
        "        })\n",
        "    logger.error(f\"RequestValidationError: {error_details}\")\n",
        "    return JSONResponse(\n",
        "        status_code=422,\n",
        "        content={\"detail\": \"Request validation failed\", \"errors\": error_details},\n",
        "    )\n",
        "\n",
        "# --- (ì´í•˜ ì „ì—­ ë³€ìˆ˜ ë° ì„œë²„ ë¡œë”© ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼) ---\n",
        "model, tokenizer, styles_info, positive_token_id, negative_token_id = None, None, None, None, None\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "@app.on_event(\"startup\")\n",
        "def load_resources():\n",
        "    # ... (ì´ì „ê³¼ ë™ì¼í•œ load_resources í•¨ìˆ˜)\n",
        "    global model, tokenizer, styles_info, positive_token_id, negative_token_id\n",
        "    logger.info(\"âœ… ìµœì¢… DPO ëª¨ë¸ ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    adapter_path = \"/content/content/gemma-fashion-dpo-final-v3\"\n",
        "    quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", quantization_config=quantization_config, device_map=\"auto\")\n",
        "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "    model.eval()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    positive_token_id = tokenizer.encode(\"ê¸ì •ì \", add_special_tokens=False)[0]\n",
        "    negative_token_id = tokenizer.encode(\"ë¶€ì •ì \", add_special_tokens=False)[0]\n",
        "    logger.info(\"âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ!\")\n",
        "    try:\n",
        "        styles_df = pd.read_csv(\"styles.csv\", on_bad_lines='skip', dtype={'id': int}).set_index('id')\n",
        "        styles_info = styles_df.to_dict('index')\n",
        "        logger.info(\"âœ… styles.csv ë¡œë“œ ì™„ë£Œ!\")\n",
        "    except FileNotFoundError:\n",
        "        logger.warning(\"âš ï¸ styles.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´, ë¹ˆ ë°ì´í„°ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "        styles_info = {}\n",
        "\n",
        "# --- (ì´í•˜ ëª¨ë“  ì¶”ì²œ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼) ---\n",
        "def get_item_description(item_id, temp_styles_info):\n",
        "    info = temp_styles_info.get(item_id, {})\n",
        "    season = info.get('season', 'All')\n",
        "    return f\"{info.get('baseColor', '')} {info.get('articleType', '')} ({season})\".strip()\n",
        "class ClosetItem(BaseModel):\n",
        "    id: int; gender: str; masterCategory: str; subCategory: str\n",
        "    articleType: str; baseColor: str; season: str; usage: str\n",
        "class OutfitRequest(BaseModel):\n",
        "    closet: List[ClosetItem]; event: str; temperature: float; condition: str; gender: str\n",
        "@app.post(\"/recommend_outfit\")\n",
        "def recommend_outfit(req: OutfitRequest):\n",
        "    start_time = time.time()\n",
        "    request_closet_info = {item.id: item.dict() for item in req.closet}\n",
        "    temp_styles_info = styles_info.copy()\n",
        "    temp_styles_info.update(request_closet_info)\n",
        "    closet_ids = [item.id for item in req.closet]\n",
        "    temp = req.temperature; event = req.event\n",
        "    if temp <= 10: suitable_seasons = ['Winter', 'Fall']\n",
        "    else: suitable_seasons = ['Summer', 'Spring', 'All Season']\n",
        "    target_usage = ['Casual', 'Smart Casual']\n",
        "    if event in [\"Business Meeting\", \"Formal Dinner\"]: target_usage = ['Formal', 'Smart Casual']\n",
        "    elif event in [\"Gym Workout\", \"Hiking\", \"Sports\"]: target_usage = ['Sports', 'Active']\n",
        "    filtered_closet_ids = [ item_id for item_id in closet_ids if item_id in temp_styles_info and (temp_styles_info[item_id].get('season') in suitable_seasons or temp_styles_info[item_id].get('season') == 'All Season') and (temp_styles_info[item_id].get('usage') in target_usage) ]\n",
        "    if not filtered_closet_ids: return {\"error\": \"í˜„ì¬ ìƒí™©ì— ë§ëŠ” ì•„ì´í…œì´ ì˜·ì¥ì— ì—†ìŠµë‹ˆë‹¤.\"}\n",
        "    item_prompts = [f\"ìƒí™©: {req.gender}, {req.temperature}Â°C, {req.condition}, {req.event}\\nì˜·: {get_item_description(item_id, temp_styles_info)}\\nê²°ê³¼:\" for item_id in filtered_closet_ids]\n",
        "    inputs = tokenizer(item_prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad(): outputs = model(**inputs)\n",
        "    sequence_lengths = inputs['attention_mask'].sum(dim=1) - 1\n",
        "    last_token_logits = outputs.logits[torch.arange(len(filtered_closet_ids)), sequence_lengths]\n",
        "    logits_for_scoring = last_token_logits[:, [negative_token_id, positive_token_id]]\n",
        "    probs = torch.softmax(logits_for_scoring, dim=-1)\n",
        "    item_scores = probs[:, 1].tolist()\n",
        "    scored_items = {filtered_closet_ids[i]: item_scores[i] for i in range(len(filtered_closet_ids))}\n",
        "    TOP_K_ITEMS_PER_PART = 5\n",
        "    top_items_by_part = { 'Topwear': [], 'Bottomwear': [], 'Outerwear': [], 'Footwear': [], 'Full Body': [] }\n",
        "    outerwear_types = ['Jackets', 'Blazers', 'Waistcoat', 'Coat', 'Shrug', 'Cardigan', 'Nehru Jackets', 'Rain Jacket', 'Sweaters']\n",
        "    full_body_types = ['Dresses', 'Jumpsuit']\n",
        "    for item_id in filtered_closet_ids:\n",
        "        info = temp_styles_info[item_id]; part = None\n",
        "        if info.get('articleType') in full_body_types: part = 'Full Body'\n",
        "        elif info.get('articleType') in outerwear_types: part = 'Outerwear'\n",
        "        elif info.get('subCategory') == 'Topwear': part = 'Topwear'\n",
        "        elif info.get('subCategory') == 'Bottomwear': part = 'Bottomwear'\n",
        "        elif info.get('masterCategory') == 'Footwear': part = 'Footwear'\n",
        "        if part: top_items_by_part[part].append(item_id)\n",
        "    for part, items in top_items_by_part.items():\n",
        "        items.sort(key=lambda x: scored_items.get(x, 0), reverse=True)\n",
        "        top_items_by_part[part] = items[:TOP_K_ITEMS_PER_PART]\n",
        "    base_combinations = list(product(top_items_by_part.get('Topwear', []), top_items_by_part.get('Bottomwear', []), top_items_by_part.get('Footwear', [])))\n",
        "    outer_combinations = list(product(top_items_by_part.get('Topwear', []), top_items_by_part.get('Bottomwear', []), top_items_by_part.get('Outerwear', []), top_items_by_part.get('Footwear', [])))\n",
        "    full_body_combinations = list(product(top_items_by_part.get('Full Body', []), top_items_by_part.get('Footwear', [])))\n",
        "    all_combinations = [c for c in base_combinations + outer_combinations + full_body_combinations if c]\n",
        "    if not all_combinations: return {\"error\": \"ìƒìœ„ ì•„ì´í…œë“¤ë¡œ ìœ íš¨í•œ ì¡°í•©ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"}\n",
        "    prompts = [ f\"ìƒí™©: {req.gender}, {req.temperature}Â°C, {req.condition}, {req.event}\\nì˜·: {', '.join([get_item_description(id, temp_styles_info) for id in combo])}\\nê²°ê³¼:\" for combo in all_combinations ]\n",
        "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad(): outputs = model(**inputs)\n",
        "    sequence_lengths = inputs['attention_mask'].sum(dim=1) - 1\n",
        "    last_token_logits = outputs.logits[torch.arange(len(all_combinations)), sequence_lengths]\n",
        "    logits_for_scoring = last_token_logits[:, [negative_token_id, positive_token_id]]\n",
        "    probs = torch.softmax(logits_for_scoring, dim=-1)\n",
        "    all_scores = probs[:, 1].tolist()\n",
        "    best_score_index = all_scores.index(max(all_scores))\n",
        "    best_score = all_scores[best_score_index]\n",
        "    best_combo = all_combinations[best_score_index]\n",
        "    best_combo_ids = [int(id_val) for id_val in best_combo if id_val is not None]\n",
        "    outfit_str = \", \".join([get_item_description(id, temp_styles_info) for id in best_combo_ids])\n",
        "    best_outfit_info = {\"description\": outfit_str, \"ids\": best_combo_ids}\n",
        "    explanation = f\"ê¸ì •ì : {req.temperature}Â°Cì˜ {req.condition} ë‚ ì”¨ì— ì§„í–‰ë˜ëŠ” {req.event}ì— ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.\"\n",
        "    end_time = time.time()\n",
        "    return {\"best_combination\": best_outfit_info, \"explanation\": explanation, \"best_score\": best_score, \"processing_time\": end_time - start_time}\n",
        "\n",
        "print(\"âœ… 'serve_final.py' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562,
          "referenced_widgets": [
            "651e87aab2834d9097d77ecf58568064",
            "b086544b4eb64143ad75580662f80e05",
            "c050b9128636421da8eec3ce683f8b8c",
            "7536ab80828149d2a5be66dca850bf14",
            "1ce958cf02ca4d179b4223d55f7949fa",
            "ceb87a3596b54561bb1e6298ab32f3cb",
            "65de6acb19bc4a01b4ee6fb98eaff3f8",
            "a96cc2c533564abdabd4287a7298ea0c",
            "f8d00472d8aa40298a0127340bc3d95c",
            "d971e2f173c240f7b1c55d697e8dc856",
            "2ee30fc3dda94a009b6a119a12058014"
          ]
        },
        "id": "SWXp4hfsVDaM",
        "outputId": "8c06ec47-efab-4454-e204-c607f34e16d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… FastAPI ì„œë²„ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤...\n",
            "â³ ì„œë²„ê°€ ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [22481]\n",
            "INFO:     Waiting for application startup.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… 'serve_final.py' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "651e87aab2834d9097d77ecf58568064"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n",
            "INFO:     127.0.0.1:42426 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "âœ… ì„œë²„ê°€ ì‘ë‹µí•˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤!\n",
            "\n",
            "ğŸ‰ ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. API ì£¼ì†Œ: NgrokTunnel: \"https://58fea4bf219d.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "ì´ì œ ì´ ì£¼ì†Œë¥¼ test_api.pyì— ë„£ê³  ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\n",
            "INFO:     27.0.238.70:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     27.0.238.70:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     61.42.109.11:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "# --- 5. ì„œë²„ ì‹¤í–‰ ë° ngrok í„°ë„ ìƒì„± ---\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "def run_app():\n",
        "  uvicorn.run(\"serve_final:app\", host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()\n",
        "print(\"\\nâœ… FastAPI ì„œë²„ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤...\")\n",
        "\n",
        "print(\"â³ ì„œë²„ê°€ ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤...\")\n",
        "start_time = time.time()\n",
        "server_ready = False\n",
        "while time.time() - start_time < 600:\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:8000/\", timeout=5)\n",
        "        if response.status_code == 404:\n",
        "            print(\"âœ… ì„œë²„ê°€ ì‘ë‹µí•˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤!\")\n",
        "            server_ready = True\n",
        "            break\n",
        "    except requests.exceptions.ConnectionError: time.sleep(5); print(\"...\")\n",
        "if not server_ready:\n",
        "    print(\"âŒ 10ë¶„ì´ ì§€ë‚˜ë„ ì„œë²„ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    NGROK_TOKEN = \"31HHkLEWGt90qDRoAWd6BqiGL9K_5fJsXN7LgijbtcAVwkwAS\" # ğŸš¨\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    ngrok.kill()\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"\\nğŸ‰ ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. API ì£¼ì†Œ: {public_url}\")\n",
        "    print(\"ì´ì œ ì´ ì£¼ì†Œë¥¼ test_api.pyì— ë„£ê³  ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "\n",
        "thread.join()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "651e87aab2834d9097d77ecf58568064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b086544b4eb64143ad75580662f80e05",
              "IPY_MODEL_c050b9128636421da8eec3ce683f8b8c",
              "IPY_MODEL_7536ab80828149d2a5be66dca850bf14"
            ],
            "layout": "IPY_MODEL_1ce958cf02ca4d179b4223d55f7949fa"
          }
        },
        "b086544b4eb64143ad75580662f80e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceb87a3596b54561bb1e6298ab32f3cb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_65de6acb19bc4a01b4ee6fb98eaff3f8",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "c050b9128636421da8eec3ce683f8b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a96cc2c533564abdabd4287a7298ea0c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8d00472d8aa40298a0127340bc3d95c",
            "value": 2
          }
        },
        "7536ab80828149d2a5be66dca850bf14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d971e2f173c240f7b1c55d697e8dc856",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2ee30fc3dda94a009b6a119a12058014",
            "value": "â€‡2/2â€‡[00:21&lt;00:00,â€‡â€‡9.05s/it]"
          }
        },
        "1ce958cf02ca4d179b4223d55f7949fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb87a3596b54561bb1e6298ab32f3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65de6acb19bc4a01b4ee6fb98eaff3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a96cc2c533564abdabd4287a7298ea0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d00472d8aa40298a0127340bc3d95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d971e2f173c240f7b1c55d697e8dc856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee30fc3dda94a009b6a119a12058014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}