{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6233766233766234,
  "eval_steps": 500,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05194805194805195,
      "grad_norm": 8.945502281188965,
      "learning_rate": 9.938950460359912e-06,
      "logits/chosen": -19.508167266845703,
      "logits/rejected": -19.40686798095703,
      "logps/chosen": -209.0967254638672,
      "logps/rejected": -215.5736846923828,
      "loss": 0.6829,
      "rewards/accuracies": 0.5099999904632568,
      "rewards/chosen": -0.08600431680679321,
      "rewards/margins": 0.024536065757274628,
      "rewards/rejected": -0.11054036766290665,
      "step": 25
    },
    {
      "epoch": 0.1038961038961039,
      "grad_norm": 11.886387825012207,
      "learning_rate": 9.747161496231359e-06,
      "logits/chosen": -19.46002769470215,
      "logits/rejected": -19.398773193359375,
      "logps/chosen": -214.9589385986328,
      "logps/rejected": -221.0380096435547,
      "loss": 0.655,
      "rewards/accuracies": 0.6225000023841858,
      "rewards/chosen": -0.33390653133392334,
      "rewards/margins": 0.10455775260925293,
      "rewards/rejected": -0.4384642541408539,
      "step": 50
    },
    {
      "epoch": 0.15584415584415584,
      "grad_norm": 8.340067863464355,
      "learning_rate": 9.429607890750863e-06,
      "logits/chosen": -19.538793563842773,
      "logits/rejected": -19.476436614990234,
      "logps/chosen": -210.509765625,
      "logps/rejected": -217.4280242919922,
      "loss": 0.6199,
      "rewards/accuracies": 0.6899999976158142,
      "rewards/chosen": 0.0019289113115519285,
      "rewards/margins": 0.21339361369609833,
      "rewards/rejected": -0.21146470308303833,
      "step": 75
    },
    {
      "epoch": 0.2077922077922078,
      "grad_norm": 8.735530853271484,
      "learning_rate": 8.994702463944657e-06,
      "logits/chosen": -19.5772647857666,
      "logits/rejected": -19.484960556030273,
      "logps/chosen": -213.37808227539062,
      "logps/rejected": -221.4005889892578,
      "loss": 0.5957,
      "rewards/accuracies": 0.7200000286102295,
      "rewards/chosen": -0.009360500611364841,
      "rewards/margins": 0.31251946091651917,
      "rewards/rejected": -0.32187995314598083,
      "step": 100
    },
    {
      "epoch": 0.2597402597402597,
      "grad_norm": 10.69072437286377,
      "learning_rate": 8.453966990470656e-06,
      "logits/chosen": -19.50678062438965,
      "logits/rejected": -19.413339614868164,
      "logps/chosen": -213.36929321289062,
      "logps/rejected": -220.64405822753906,
      "loss": 0.5814,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.08018961548805237,
      "rewards/margins": 0.3829367458820343,
      "rewards/rejected": -0.46312636137008667,
      "step": 125
    },
    {
      "epoch": 0.3116883116883117,
      "grad_norm": 12.60034465789795,
      "learning_rate": 7.821726957873728e-06,
      "logits/chosen": -19.432201385498047,
      "logits/rejected": -19.35898208618164,
      "logps/chosen": -210.2691192626953,
      "logps/rejected": -220.6486358642578,
      "loss": 0.5599,
      "rewards/accuracies": 0.6825000047683716,
      "rewards/chosen": -0.0868414044380188,
      "rewards/margins": 0.43224892020225525,
      "rewards/rejected": -0.5190903544425964,
      "step": 150
    },
    {
      "epoch": 0.36363636363636365,
      "grad_norm": 14.775259971618652,
      "learning_rate": 7.114732047202433e-06,
      "logits/chosen": -19.44378089904785,
      "logits/rejected": -19.324216842651367,
      "logps/chosen": -214.71255493164062,
      "logps/rejected": -224.97528076171875,
      "loss": 0.5554,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.37724605202674866,
      "rewards/margins": 0.469295859336853,
      "rewards/rejected": -0.8465418815612793,
      "step": 175
    },
    {
      "epoch": 0.4155844155844156,
      "grad_norm": 11.220905303955078,
      "learning_rate": 6.35171239044171e-06,
      "logits/chosen": -19.533920288085938,
      "logits/rejected": -19.460105895996094,
      "logps/chosen": -217.49610900878906,
      "logps/rejected": -227.0525360107422,
      "loss": 0.5415,
      "rewards/accuracies": 0.7200000286102295,
      "rewards/chosen": -0.6238962411880493,
      "rewards/margins": 0.5567169785499573,
      "rewards/rejected": -1.1806132793426514,
      "step": 200
    },
    {
      "epoch": 0.4675324675324675,
      "grad_norm": 9.546428680419922,
      "learning_rate": 5.55288236065495e-06,
      "logits/chosen": -19.626995086669922,
      "logits/rejected": -19.515535354614258,
      "logps/chosen": -216.12339782714844,
      "logps/rejected": -227.27337646484375,
      "loss": 0.5362,
      "rewards/accuracies": 0.7174999713897705,
      "rewards/chosen": -0.6665785908699036,
      "rewards/margins": 0.6111074090003967,
      "rewards/rejected": -1.2776859998703003,
      "step": 225
    },
    {
      "epoch": 0.5194805194805194,
      "grad_norm": 11.589221954345703,
      "learning_rate": 4.739405040723798e-06,
      "logits/chosen": -19.589731216430664,
      "logits/rejected": -19.51112174987793,
      "logps/chosen": -219.83489990234375,
      "logps/rejected": -231.5000457763672,
      "loss": 0.508,
      "rewards/accuracies": 0.7475000023841858,
      "rewards/chosen": -0.7198312282562256,
      "rewards/margins": 0.6969127655029297,
      "rewards/rejected": -1.4167442321777344,
      "step": 250
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 10.173534393310547,
      "learning_rate": 3.932831558300074e-06,
      "logits/chosen": -19.609329223632812,
      "logits/rejected": -19.525314331054688,
      "logps/chosen": -213.29466247558594,
      "logps/rejected": -225.40496826171875,
      "loss": 0.5381,
      "rewards/accuracies": 0.7149999737739563,
      "rewards/chosen": -0.5570436716079712,
      "rewards/margins": 0.6484420299530029,
      "rewards/rejected": -1.2054855823516846,
      "step": 275
    },
    {
      "epoch": 0.6233766233766234,
      "grad_norm": 13.079180717468262,
      "learning_rate": 3.1545301404435756e-06,
      "logits/chosen": -19.495689392089844,
      "logits/rejected": -19.390214920043945,
      "logps/chosen": -217.50355529785156,
      "logps/rejected": -230.92161560058594,
      "loss": 0.5007,
      "rewards/accuracies": 0.7475000023841858,
      "rewards/chosen": -0.6635721325874329,
      "rewards/margins": 0.7459120750427246,
      "rewards/rejected": -1.4094842672348022,
      "step": 300
    }
  ],
  "logging_steps": 25,
  "max_steps": 482,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
