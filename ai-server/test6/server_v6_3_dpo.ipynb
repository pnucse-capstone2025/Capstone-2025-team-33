{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "33e94d12dd6b4e9ca8a1b7df296fc5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_318759094f844485b706f715aaa5652b",
              "IPY_MODEL_594584672bec40d0ab6404c95fe3cbde",
              "IPY_MODEL_380dce4cb001447ab17fb5cf5f98fabe"
            ],
            "layout": "IPY_MODEL_f533b1bf0f4a499ab3431bfa1b662038"
          }
        },
        "318759094f844485b706f715aaa5652b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7cc48422fda49ddad1a1baf7a4db96a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ad3aa20c4204920b93bfd211cea51c8",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "594584672bec40d0ab6404c95fe3cbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77a72adde19a46e38c017f91e9b9ba4b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75746e8bc25d41dc8a20b948c8ff1a4c",
            "value": 2
          }
        },
        "380dce4cb001447ab17fb5cf5f98fabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a24d4fb92e64fbf8c0cbe37f0309eb5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c160e78899a1432e9ef25d56b30a27e5",
            "value": "â€‡2/2â€‡[00:19&lt;00:00,â€‡â€‡8.26s/it]"
          }
        },
        "f533b1bf0f4a499ab3431bfa1b662038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cc48422fda49ddad1a1baf7a4db96a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad3aa20c4204920b93bfd211cea51c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77a72adde19a46e38c017f91e9b9ba4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75746e8bc25d41dc8a20b948c8ff1a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a24d4fb92e64fbf8c0cbe37f0309eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c160e78899a1432e9ef25d56b30a27e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WxzBr-8UUqTt"
      },
      "outputs": [],
      "source": [
        "# --- 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ---\n",
        "!pip install -q -U transformers peft accelerate trl datasets huggingface_hub fastapi \"uvicorn[standard]\" pyngrok bitsandbytes \"pandas==2.2.2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. íŒŒì¼ ì—…ë¡œë“œ ë° ë¡œê·¸ì¸ ---\n",
        "from google.colab import files\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "print(\"--- ğŸ“‚ íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤ ---\")\n",
        "files_to_upload = ['gemma-fashion-dpo-final-v3.zip', 'styles.csv']\n",
        "for filename in files_to_upload:\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"\\n'{filename}'ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
        "        files.upload()\n",
        "    else:\n",
        "        print(f\"'{filename}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba6nuss7UyIt",
        "outputId": "2a547671-801a-4661-ebde-1168cbea5207"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ğŸ“‚ íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤ ---\n",
            "'gemma-fashion-dpo-final-v3.zip'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
            "'styles.csv'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. ëª¨ë¸ í´ë” ì••ì¶• í•´ì œ ë° 'ìë™ ê²½ë¡œ íƒì§€' ---\n",
        "print(\"\\nëª¨ë¸ í´ë” ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤...\")\n",
        "!unzip -q -o gemma-fashion-dpo-final-v3.zip -d /content/\n",
        "\n",
        "ADAPTER_PATH_FOUND = \"\"\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if 'adapter_config.json' in files:\n",
        "        ADAPTER_PATH_FOUND = root\n",
        "        break\n",
        "\n",
        "if not ADAPTER_PATH_FOUND:\n",
        "    raise FileNotFoundError(\"ì••ì¶• í•´ì œ í›„ 'adapter_config.json'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Zip íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "print(f\"âœ… 'adapter_config.json'ì˜ ì •í™•í•œ ê²½ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {ADAPTER_PATH_FOUND}\")\n",
        "# â— ì°¾ì€ ê²½ë¡œë¥¼ í™˜ê²½ ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
        "os.environ['ADAPTER_PATH'] = ADAPTER_PATH_FOUND\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSLsuKKYU2BL",
        "outputId": "d51ae3a7-d31b-49e5-955a-0ada400ec399"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ëª¨ë¸ í´ë” ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤...\n",
            "âœ… 'adapter_config.json'ì˜ ì •í™•í•œ ê²½ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: /content/content/gemma-fashion-dpo-final-v3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. API ì„œë²„ ì½”ë“œ ì‘ì„± (serve_final.py) - ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ ë²„ì „\n",
        "\n",
        "%%writefile serve_final.py\n",
        "\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "import time\n",
        "import random\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "import uvicorn\n",
        "import logging\n",
        "\n",
        "# --- ê¸°ë³¸ ì„¤ì • ---\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "app = FastAPI()\n",
        "\n",
        "# --- ì „ì—­ ë³€ìˆ˜ ---\n",
        "model, tokenizer, styles_info, positive_token_id, negative_token_id = None, None, None, None, None\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "outerwear_types = ['Jackets', 'Blazers', 'Waistcoat', 'Coat', 'Shrug', 'Cardigan', 'Nehru Jackets', 'Rain Jacket', 'Sweaters']\n",
        "full_body_types = ['Dresses', 'Jumpsuit']\n",
        "\n",
        "# --- ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë”© ---\n",
        "@app.on_event(\"startup\")\n",
        "def load_resources():\n",
        "    global model, tokenizer, styles_info, positive_token_id, negative_token_id\n",
        "    logger.info(\"âœ… ìµœì¢… DPO ëª¨ë¸ ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    adapter_path = \"/content/content/gemma-fashion-dpo-final-v3\"\n",
        "    quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", quantization_config=quantization_config, device_map=\"auto\")\n",
        "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "    model.eval()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    positive_token_id = tokenizer.encode(\"ê¸ì •ì \", add_special_tokens=False)[0]\n",
        "    negative_token_id = tokenizer.encode(\"ë¶€ì •ì \", add_special_tokens=False)[0]\n",
        "    logger.info(\"âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ!\")\n",
        "    styles_df = pd.read_csv(\"styles.csv\", on_bad_lines='skip', dtype={'id': int}).set_index('id')\n",
        "    styles_info = styles_df.to_dict('index')\n",
        "    logger.info(\"âœ… styles.csv ë¡œë“œ ì™„ë£Œ!\")\n",
        "\n",
        "# --- í—¬í¼ í•¨ìˆ˜ ---\n",
        "def get_item_description(item_id):\n",
        "    if item_id not in styles_info: return \"\"\n",
        "    info = styles_info[item_id]; season = info.get('season', 'All')\n",
        "    return f\"{info.get('baseColour', '')} {info.get('articleType', '')} ({season})\".strip()\n",
        "\n",
        "# --- â˜… NEW: ê·œì¹™ ê¸°ë°˜ 'ìƒì‹ ì ìˆ˜' ê³„ì‚° í•¨ìˆ˜ ---\n",
        "def calculate_rule_score(outfit_ids: List[int], context: Dict[str, Any]) -> float:\n",
        "    \"\"\"ìƒí™©ê³¼ ì˜·ì˜ ìš©ë„(usage), ì•„ìš°í„° ì°©ìš© ì—¬ë¶€ ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¸°ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    score = 0.0\n",
        "    items_info = [styles_info.get(id) for id in outfit_ids if id in styles_info]\n",
        "    event = context['event']\n",
        "    temp = context['temperature']\n",
        "\n",
        "    # ì•„ìš°í„° ê°€ì¤‘ì¹˜: 18Â°C ì´í•˜ì¼ ë•Œ ì•„ìš°í„°ê°€ í¬í•¨ëœ ì¡°í•©ì— ê°•ë ¥í•œ ë³´ë„ˆìŠ¤ ì ìˆ˜ ë¶€ì—¬\n",
        "    has_outer = any(info and info.get('articleType') in outerwear_types for info in items_info)\n",
        "    if temp <= 18 and has_outer:\n",
        "        score += 1.0 # AI ì ìˆ˜ ìŠ¤ì¼€ì¼(0~1)ì— ë§ì¶° í° ê°€ì¤‘ì¹˜ ë¶€ì—¬\n",
        "    elif temp > 22 and has_outer:\n",
        "        score -= 2.0 # ë”ìš¸ ë•Œ ì•„ìš°í„°ëŠ” í° ê°ì \n",
        "\n",
        "    # ê²©ì‹ ê°€ì¤‘ì¹˜: ê²©ì‹ìˆëŠ” ìë¦¬ì— ëª¨ë“  ì˜·ì˜ usageê°€ Formal/Smart Casualì´ë©´ ë³´ë„ˆìŠ¤ ì ìˆ˜\n",
        "    if event in [\"Business Meeting\", \"Office Meeting\", \"Formal Dinner\", \"Job Interview\"]:\n",
        "        if all(info and info.get('usage') in ['Formal', 'Smart Casual'] for info in items_info):\n",
        "            score += 1.0\n",
        "        else: # ê²©ì‹ì— ë§ì§€ ì•ŠëŠ” ì˜·ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê°ì \n",
        "            score -= 1.0\n",
        "\n",
        "    return score\n",
        "\n",
        "class OutfitRequest(BaseModel):\n",
        "    closet: List[int]; event: str; temperature: float; condition: str; gender: str\n",
        "\n",
        "@app.post(\"/recommend_outfit\")\n",
        "def recommend_outfit(req: OutfitRequest):\n",
        "    start_time = time.time()\n",
        "    # (ì´ì „ê³¼ ë™ì¼í•œ í•„í„°ë§ ë° ë¶„ë¥˜, 2ë‹¨ê³„ í‰ê°€ ë¡œì§)\n",
        "    # ... (ìƒëµ) ...\n",
        "    temp = req.temperature; event = req.event\n",
        "    if temp <= 10: suitable_seasons = ['Winter', 'Fall']\n",
        "    else: suitable_seasons = ['Summer', 'Spring', 'All Season']\n",
        "    target_usage = ['Casual', 'Smart Casual']\n",
        "    if event in [\"Business Meeting\", \"Formal Dinner\", \"Office Meeting\"]: target_usage = ['Formal', 'Smart Casual']\n",
        "    elif event in [\"Gym Workout\", \"Hiking\", \"Sports\"]: target_usage = ['Sports', 'Active']\n",
        "    def filter_and_classify_closet(ids_to_filter, strict_usage_check=True):\n",
        "        items_classified = { 'Topwear': [], 'Bottomwear': [], 'Outerwear': [], 'Footwear': [], 'Full Body': [] }\n",
        "        for item_id in ids_to_filter:\n",
        "            if item_id in styles_info:\n",
        "                info = styles_info[item_id]\n",
        "                is_season_ok = info.get('season') in suitable_seasons or info.get('season') == 'All Season'\n",
        "                is_usage_ok = not strict_usage_check or info.get('usage') in target_usage\n",
        "                if is_season_ok and is_usage_ok:\n",
        "                    sub_category = info.get('subCategory', ''); article_type = info.get('articleType', ''); master_category = info.get('masterCategory', '')\n",
        "                    if article_type in full_body_types: items_classified['Full Body'].append(item_id)\n",
        "                    elif article_type in outerwear_types: items_classified['Outerwear'].append(item_id)\n",
        "                    elif sub_category == 'Topwear': items_classified['Topwear'].append(item_id)\n",
        "                    elif sub_category == 'Bottomwear': items_classified['Bottomwear'].append(item_id)\n",
        "                    elif master_category == 'Footwear': items_classified['Footwear'].append(item_id)\n",
        "        return items_classified\n",
        "    closet_items = filter_and_classify_closet(req.closet, strict_usage_check=True)\n",
        "    if not (closet_items['Topwear'] and closet_items['Bottomwear'] and closet_items['Footwear']) and not (closet_items['Full Body'] and closet_items['Footwear']):\n",
        "        closet_items = filter_and_classify_closet(req.closet, strict_usage_check=False)\n",
        "    all_filtered_items = list(set(item for part_items in closet_items.values() for item in part_items))\n",
        "    if len(all_filtered_items) > 40: all_filtered_items = random.sample(all_filtered_items, 40)\n",
        "    if not all_filtered_items: return {\"error\": \"í˜„ì¬ ìƒí™©ì— ë§ëŠ” ì•„ì´í…œì´ ì˜·ì¥ì— ì—†ìŠµë‹ˆë‹¤.\"}\n",
        "    item_prompts = [f\"ìƒí™©: {req.gender}, {req.temperature}Â°C, {req.condition}, {req.event}\\nì˜·: {get_item_description(item_id)}\\nê²°ê³¼:\" for item_id in all_filtered_items]\n",
        "    inputs = tokenizer(item_prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad(): outputs = model(**inputs)\n",
        "    sequence_lengths = inputs['attention_mask'].sum(dim=1) - 1\n",
        "    last_token_logits = outputs.logits[torch.arange(len(all_filtered_items)), sequence_lengths]\n",
        "    logits_for_scoring = last_token_logits[:, [negative_token_id, positive_token_id]]\n",
        "    probs = torch.softmax(logits_for_scoring, dim=-1)\n",
        "    item_scores = probs[:, 1].tolist()\n",
        "    scored_items = {all_filtered_items[i]: item_scores[i] for i in range(len(all_filtered_items))}\n",
        "    TOP_K_ITEMS_PER_PART = 7\n",
        "    top_items_by_part = { part: sorted(items, key=lambda x: scored_items.get(x, 0), reverse=True)[:TOP_K_ITEMS_PER_PART] for part, items in closet_items.items() }\n",
        "    base_combinations = list(product(top_items_by_part.get('Topwear', []), top_items_by_part.get('Bottomwear', []), top_items_by_part.get('Footwear', [])))\n",
        "    outer_combinations = list(product(top_items_by_part.get('Topwear', []), top_items_by_part.get('Bottomwear', []), top_items_by_part.get('Outerwear', []), top_items_by_part.get('Footwear', [])))\n",
        "    full_body_combinations = list(product(top_items_by_part.get('Full Body', []), top_items_by_part.get('Footwear', [])))\n",
        "    all_combinations = [c for c in base_combinations + outer_combinations + full_body_combinations if c]\n",
        "    if not all_combinations: return {\"error\": \"ìƒìœ„ ì•„ì´í…œë“¤ë¡œ ìœ íš¨í•œ ì¡°í•©ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"}\n",
        "\n",
        "    prompts = [ f\"ìƒí™©: {req.gender}, {req.temperature}Â°C, {req.condition}, {req.event}\\nì˜·: {', '.join([get_item_description(id) for id in combo])}\\nê²°ê³¼:\" for combo in all_combinations ]\n",
        "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad(): outputs = model(**inputs)\n",
        "    sequence_lengths = inputs['attention_mask'].sum(dim=1) - 1\n",
        "    last_token_logits = outputs.logits[torch.arange(len(all_combinations)), sequence_lengths]\n",
        "    logits_for_scoring = last_token_logits[:, [negative_token_id, positive_token_id]]\n",
        "    probs = torch.softmax(logits_for_scoring, dim=-1)\n",
        "    ai_scores = probs[:, 1].tolist()\n",
        "\n",
        "    # --- â˜… NEW: í•˜ì´ë¸Œë¦¬ë“œ ìµœì¢… ì ìˆ˜ ê³„ì‚° ---\n",
        "    final_scored_combinations = []\n",
        "    for i, combo in enumerate(all_combinations):\n",
        "        combo_ids = [id for id in combo if id is not None]\n",
        "        rule_score = calculate_rule_score(combo_ids, req.dict())\n",
        "        final_score = ai_scores[i] + rule_score\n",
        "        final_scored_combinations.append((combo, final_score))\n",
        "\n",
        "    sorted_combinations = sorted(final_scored_combinations, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    best_combo, best_score = sorted_combinations[0]\n",
        "    best_combo_ids = [int(id_val) for id_val in best_combo if id_val is not None]\n",
        "    outfit_str = \", \".join([get_item_description(id) for id in best_combo_ids])\n",
        "    best_outfit_info = {\"description\": outfit_str, \"ids\": best_combo_ids}\n",
        "    explanation = f\"ê¸ì •ì : {req.temperature}Â°Cì˜ {req.condition} ë‚ ì”¨ì— ì§„í–‰ë˜ëŠ” {req.event}ì— ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.\"\n",
        "    end_time = time.time()\n",
        "    return {\"best_combination\": best_outfit_info, \"explanation\": explanation, \"best_score\": best_score, \"processing_time\": end_time - start_time}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ie42SukU5ew",
        "outputId": "869d060e-5369-4119-816e-151a030c1cf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting serve_final.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. ì„œë²„ ì‹¤í–‰ ë° ngrok í„°ë„ ìƒì„± ---\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "def run_app():\n",
        "  uvicorn.run(\"serve_final:app\", host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()\n",
        "print(\"\\nâœ… FastAPI ì„œë²„ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤...\")\n",
        "\n",
        "print(\"â³ ì„œë²„ê°€ ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤...\")\n",
        "start_time = time.time()\n",
        "server_ready = False\n",
        "while time.time() - start_time < 600:\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:8000/\", timeout=5)\n",
        "        if response.status_code == 404:\n",
        "            print(\"âœ… ì„œë²„ê°€ ì‘ë‹µí•˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤!\")\n",
        "            server_ready = True\n",
        "            break\n",
        "    except requests.exceptions.ConnectionError: time.sleep(5); print(\"...\")\n",
        "if not server_ready:\n",
        "    print(\"âŒ 10ë¶„ì´ ì§€ë‚˜ë„ ì„œë²„ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    NGROK_TOKEN = \"31HHkLEWGt90qDRoAWd6BqiGL9K_5fJsXN7LgijbtcAVwkwAS\" # ğŸš¨\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    ngrok.kill()\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"\\nğŸ‰ ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. API ì£¼ì†Œ: {public_url}\")\n",
        "    print(\"ì´ì œ ì´ ì£¼ì†Œë¥¼ test_api.pyì— ë„£ê³  ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "\n",
        "thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997,
          "referenced_widgets": [
            "33e94d12dd6b4e9ca8a1b7df296fc5a4",
            "318759094f844485b706f715aaa5652b",
            "594584672bec40d0ab6404c95fe3cbde",
            "380dce4cb001447ab17fb5cf5f98fabe",
            "f533b1bf0f4a499ab3431bfa1b662038",
            "c7cc48422fda49ddad1a1baf7a4db96a",
            "1ad3aa20c4204920b93bfd211cea51c8",
            "77a72adde19a46e38c017f91e9b9ba4b",
            "75746e8bc25d41dc8a20b948c8ff1a4c",
            "3a24d4fb92e64fbf8c0cbe37f0309eb5",
            "c160e78899a1432e9ef25d56b30a27e5"
          ]
        },
        "id": "SWXp4hfsVDaM",
        "outputId": "fbf268d9-8ce3-4448-ee19-6dfc49ecc4e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… FastAPI ì„œë²„ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤...\n",
            "â³ ì„œë²„ê°€ ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤...\n",
            "...\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [24222]\n",
            "INFO:     Waiting for application startup.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33e94d12dd6b4e9ca8a1b7df296fc5a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n",
            "...\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n",
            "...\n",
            "INFO:     127.0.0.1:34878 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "âœ… ì„œë²„ê°€ ì‘ë‹µí•˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤!\n",
            "\n",
            "ğŸ‰ ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. API ì£¼ì†Œ: NgrokTunnel: \"https://39f17048bb40.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "ì´ì œ ì´ ì£¼ì†Œë¥¼ test_api.pyì— ë„£ê³  ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-01T12:57:06+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2770823529.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ì´ì œ ì´ ì£¼ì†Œë¥¼ test_api.pyì— ë„£ê³  ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}