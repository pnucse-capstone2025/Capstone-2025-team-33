{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "33e94d12dd6b4e9ca8a1b7df296fc5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_318759094f844485b706f715aaa5652b",
              "IPY_MODEL_594584672bec40d0ab6404c95fe3cbde",
              "IPY_MODEL_380dce4cb001447ab17fb5cf5f98fabe"
            ],
            "layout": "IPY_MODEL_f533b1bf0f4a499ab3431bfa1b662038"
          }
        },
        "318759094f844485b706f715aaa5652b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7cc48422fda49ddad1a1baf7a4db96a",
            "placeholder": "​",
            "style": "IPY_MODEL_1ad3aa20c4204920b93bfd211cea51c8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "594584672bec40d0ab6404c95fe3cbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77a72adde19a46e38c017f91e9b9ba4b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75746e8bc25d41dc8a20b948c8ff1a4c",
            "value": 2
          }
        },
        "380dce4cb001447ab17fb5cf5f98fabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a24d4fb92e64fbf8c0cbe37f0309eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_c160e78899a1432e9ef25d56b30a27e5",
            "value": " 2/2 [00:19&lt;00:00,  8.26s/it]"
          }
        },
        "f533b1bf0f4a499ab3431bfa1b662038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cc48422fda49ddad1a1baf7a4db96a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad3aa20c4204920b93bfd211cea51c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77a72adde19a46e38c017f91e9b9ba4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75746e8bc25d41dc8a20b948c8ff1a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a24d4fb92e64fbf8c0cbe37f0309eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c160e78899a1432e9ef25d56b30a27e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WxzBr-8UUqTt"
      },
      "outputs": [],
      "source": [
        "# --- 1. 필수 라이브러리 설치 ---\n",
        "!pip install -q -U transformers peft accelerate trl datasets huggingface_hub fastapi \"uvicorn[standard]\" pyngrok bitsandbytes \"pandas==2.2.2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. 파일 업로드 및 로그인 ---\n",
        "from google.colab import files\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "print(\"--- 📂 파일들을 업로드합니다 ---\")\n",
        "files_to_upload = ['gemma-fashion-dpo-final-v3.zip', 'styles.csv']\n",
        "for filename in files_to_upload:\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"\\n'{filename}'을 업로드해주세요.\")\n",
        "        files.upload()\n",
        "    else:\n",
        "        print(f\"'{filename}'이(가) 이미 존재합니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba6nuss7UyIt",
        "outputId": "2a547671-801a-4661-ebde-1168cbea5207"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 📂 파일들을 업로드합니다 ---\n",
            "'gemma-fashion-dpo-final-v3.zip'이(가) 이미 존재합니다.\n",
            "'styles.csv'이(가) 이미 존재합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. 모델 폴더 압축 해제 및 '자동 경로 탐지' ---\n",
        "print(\"\\n모델 폴더 압축을 해제합니다...\")\n",
        "!unzip -q -o gemma-fashion-dpo-final-v3.zip -d /content/\n",
        "\n",
        "ADAPTER_PATH_FOUND = \"\"\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if 'adapter_config.json' in files:\n",
        "        ADAPTER_PATH_FOUND = root\n",
        "        break\n",
        "\n",
        "if not ADAPTER_PATH_FOUND:\n",
        "    raise FileNotFoundError(\"압축 해제 후 'adapter_config.json'을 찾을 수 없습니다. Zip 파일을 확인해주세요.\")\n",
        "\n",
        "print(f\"✅ 'adapter_config.json'의 정확한 경로를 찾았습니다: {ADAPTER_PATH_FOUND}\")\n",
        "# ❗ 찾은 경로를 환경 변수에 저장합니다.\n",
        "os.environ['ADAPTER_PATH'] = ADAPTER_PATH_FOUND\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSLsuKKYU2BL",
        "outputId": "d51ae3a7-d31b-49e5-955a-0ada400ec399"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "모델 폴더 압축을 해제합니다...\n",
            "✅ 'adapter_config.json'의 정확한 경로를 찾았습니다: /content/content/gemma-fashion-dpo-final-v3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. API 서버 코드 작성 (serve_final.py) - 최종 하이브리드 스코어링 버전\n",
        "\n",
        "%%writefile serve_final.py\n",
        "\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "import time\n",
        "import random\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "import uvicorn\n",
        "import logging\n",
        "\n",
        "# --- 기본 설정 ---\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "app = FastAPI()\n",
        "\n",
        "# --- 전역 변수 ---\n",
        "model, tokenizer, styles_info, positive_token_id, negative_token_id = None, None, None, None, None\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "outerwear_types = ['Jackets', 'Blazers', 'Waistcoat', 'Coat', 'Shrug', 'Cardigan', 'Nehru Jackets', 'Rain Jacket', 'Sweaters']\n",
        "full_body_types = ['Dresses', 'Jumpsuit']\n",
        "\n",
        "# --- 서버 시작 시 모델 로딩 ---\n",
        "@app.on_event(\"startup\")\n",
        "def load_resources():\n",
        "    global model, tokenizer, styles_info, positive_token_id, negative_token_id\n",
        "    logger.info(\"✅ 최종 DPO 모델 로딩을 시작합니다...\")\n",
        "    adapter_path = \"/content/content/gemma-fashion-dpo-final-v3\"\n",
        "    quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", quantization_config=quantization_config, device_map=\"auto\")\n",
        "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "    model.eval()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    positive_token_id = tokenizer.encode(\"긍정적\", add_special_tokens=False)[0]\n",
        "    negative_token_id = tokenizer.encode(\"부정적\", add_special_tokens=False)[0]\n",
        "    logger.info(\"✅ 모델 및 토크나이저 로딩 완료!\")\n",
        "    styles_df = pd.read_csv(\"styles.csv\", on_bad_lines='skip', dtype={'id': int}).set_index('id')\n",
        "    styles_info = styles_df.to_dict('index')\n",
        "    logger.info(\"✅ styles.csv 로드 완료!\")\n",
        "\n",
        "# --- 헬퍼 함수 ---\n",
        "def get_item_description(item_id):\n",
        "    if item_id not in styles_info: return \"\"\n",
        "    info = styles_info[item_id]; season = info.get('season', 'All')\n",
        "    return f\"{info.get('baseColour', '')} {info.get('articleType', '')} ({season})\".strip()\n",
        "\n",
        "# --- ★ NEW: 규칙 기반 '상식 점수' 계산 함수 ---\n",
        "def calculate_rule_score(outfit_ids: List[int], context: Dict[str, Any]) -> float:\n",
        "    \"\"\"상황과 옷의 용도(usage), 아우터 착용 여부 등을 기준으로 점수를 매기는 함수\"\"\"\n",
        "    score = 0.0\n",
        "    items_info = [styles_info.get(id) for id in outfit_ids if id in styles_info]\n",
        "    event = context['event']\n",
        "    temp = context['temperature']\n",
        "\n",
        "    # 아우터 가중치: 18°C 이하일 때 아우터가 포함된 조합에 강력한 보너스 점수 부여\n",
        "    has_outer = any(info and info.get('articleType') in outerwear_types for info in items_info)\n",
        "    if temp <= 18 and has_outer:\n",
        "        score += 1.0 # AI 점수 스케일(0~1)에 맞춰 큰 가중치 부여\n",
        "    elif temp > 22 and has_outer:\n",
        "        score -= 2.0 # 더울 때 아우터는 큰 감점\n",
        "\n",
        "    # 격식 가중치: 격식있는 자리에 모든 옷의 usage가 Formal/Smart Casual이면 보너스 점수\n",
        "    if event in [\"Business Meeting\", \"Office Meeting\", \"Formal Dinner\", \"Job Interview\"]:\n",
        "        if all(info and info.get('usage') in ['Formal', 'Smart Casual'] for info in items_info):\n",
        "            score += 1.0\n",
        "        else: # 격식에 맞지 않는 옷이 하나라도 있으면 감점\n",
        "            score -= 1.0\n",
        "\n",
        "    return score\n",
        "\n",
        "class OutfitRequest(BaseModel):\n",
        "    closet: List[int]; event: str; temperature: float; condition: str; gender: str\n",
        "\n",
        "@app.post(\"/recommend_outfit\")\n",
        "def recommend_outfit(req: OutfitRequest):\n",
        "    start_time = time.time()\n",
        "    # (이전과 동일한 필터링 및 분류, 2단계 평가 로직)\n",
        "    # ... (생략) ...\n",
        "    temp = req.temperature; event = req.event\n",
        "    if temp <= 10: suitable_seasons = ['Winter', 'Fall']\n",
        "    else: suitable_seasons = ['Summer', 'Spring', 'All Season']\n",
        "    target_usage = ['Casual', 'Smart Casual']\n",
        "    if event in [\"Business Meeting\", \"Formal Dinner\", \"Office Meeting\"]: target_usage = ['Formal', 'Smart Casual']\n",
        "    elif event in [\"Gym Workout\", \"Hiking\", \"Sports\"]: target_usage = ['Sports', 'Active']\n",
        "    def filter_and_classify_closet(ids_to_filter, strict_usage_check=True):\n",
        "        items_classified = { 'Topwear': [], 'Bottomwear': [], 'Outerwear': [], 'Footwear': [], 'Full Body': [] }\n",
        "        for item_id in ids_to_filter:\n",
        "            if item_id in styles_info:\n",
        "                info = styles_info[item_id]\n",
        "                is_season_ok = info.get('season') in suitable_seasons or info.get('season') == 'All Season'\n",
        "                is_usage_ok = not strict_usage_check or info.get('usage') in target_usage\n",
        "                if is_season_ok and is_usage_ok:\n",
        "                    sub_category = info.get('subCategory', ''); article_type = info.get('articleType', ''); master_category = info.get('masterCategory', '')\n",
        "                    if article_type in full_body_types: items_classified['Full Body'].append(item_id)\n",
        "                    elif article_type in outerwear_types: items_classified['Outerwear'].append(item_id)\n",
        "                    elif sub_category == 'Topwear': items_classified['Topwear'].append(item_id)\n",
        "                    elif sub_category == 'Bottomwear': items_classified['Bottomwear'].append(item_id)\n",
        "                    elif master_category == 'Footwear': items_classified['Footwear'].append(item_id)\n",
        "        return items_classified\n",
        "    closet_items = filter_and_classify_closet(req.closet, strict_usage_check=True)\n",
        "    if not (closet_items['Topwear'] and closet_items['Bottomwear'] and closet_items['Footwear']) and not (closet_items['Full Body'] and closet_items['Footwear']):\n",
        "        closet_items = filter_and_classify_closet(req.closet, strict_usage_check=False)\n",
        "    all_filtered_items = list(set(item for part_items in closet_items.values() for item in part_items))\n",
        "    if len(all_filtered_items) > 40: all_filtered_items = random.sample(all_filtered_items, 40)\n",
        "    if not all_filtered_items: return {\"error\": \"현재 상황에 맞는 아이템이 옷장에 없습니다.\"}\n",
        "    item_prompts = [f\"상황: {req.gender}, {req.temperature}°C, {req.condition}, {req.event}\\n옷: {get_item_description(item_id)}\\n결과:\" for item_id in all_filtered_items]\n",
        "    inputs = tokenizer(item_prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad(): outputs = model(**inputs)\n",
        "    sequence_lengths = inputs['attention_mask'].sum(dim=1) - 1\n",
        "    last_token_logits = outputs.logits[torch.arange(len(all_filtered_items)), sequence_lengths]\n",
        "    logits_for_scoring = last_token_logits[:, [negative_token_id, positive_token_id]]\n",
        "    probs = torch.softmax(logits_for_scoring, dim=-1)\n",
        "    item_scores = probs[:, 1].tolist()\n",
        "    scored_items = {all_filtered_items[i]: item_scores[i] for i in range(len(all_filtered_items))}\n",
        "    TOP_K_ITEMS_PER_PART = 7\n",
        "    top_items_by_part = { part: sorted(items, key=lambda x: scored_items.get(x, 0), reverse=True)[:TOP_K_ITEMS_PER_PART] for part, items in closet_items.items() }\n",
        "    base_combinations = list(product(top_items_by_part.get('Topwear', []), top_items_by_part.get('Bottomwear', []), top_items_by_part.get('Footwear', [])))\n",
        "    outer_combinations = list(product(top_items_by_part.get('Topwear', []), top_items_by_part.get('Bottomwear', []), top_items_by_part.get('Outerwear', []), top_items_by_part.get('Footwear', [])))\n",
        "    full_body_combinations = list(product(top_items_by_part.get('Full Body', []), top_items_by_part.get('Footwear', [])))\n",
        "    all_combinations = [c for c in base_combinations + outer_combinations + full_body_combinations if c]\n",
        "    if not all_combinations: return {\"error\": \"상위 아이템들로 유효한 조합을 만들 수 없습니다.\"}\n",
        "\n",
        "    prompts = [ f\"상황: {req.gender}, {req.temperature}°C, {req.condition}, {req.event}\\n옷: {', '.join([get_item_description(id) for id in combo])}\\n결과:\" for combo in all_combinations ]\n",
        "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad(): outputs = model(**inputs)\n",
        "    sequence_lengths = inputs['attention_mask'].sum(dim=1) - 1\n",
        "    last_token_logits = outputs.logits[torch.arange(len(all_combinations)), sequence_lengths]\n",
        "    logits_for_scoring = last_token_logits[:, [negative_token_id, positive_token_id]]\n",
        "    probs = torch.softmax(logits_for_scoring, dim=-1)\n",
        "    ai_scores = probs[:, 1].tolist()\n",
        "\n",
        "    # --- ★ NEW: 하이브리드 최종 점수 계산 ---\n",
        "    final_scored_combinations = []\n",
        "    for i, combo in enumerate(all_combinations):\n",
        "        combo_ids = [id for id in combo if id is not None]\n",
        "        rule_score = calculate_rule_score(combo_ids, req.dict())\n",
        "        final_score = ai_scores[i] + rule_score\n",
        "        final_scored_combinations.append((combo, final_score))\n",
        "\n",
        "    sorted_combinations = sorted(final_scored_combinations, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    best_combo, best_score = sorted_combinations[0]\n",
        "    best_combo_ids = [int(id_val) for id_val in best_combo if id_val is not None]\n",
        "    outfit_str = \", \".join([get_item_description(id) for id in best_combo_ids])\n",
        "    best_outfit_info = {\"description\": outfit_str, \"ids\": best_combo_ids}\n",
        "    explanation = f\"긍정적: {req.temperature}°C의 {req.condition} 날씨에 진행되는 {req.event}에 가장 잘 어울리는 스타일입니다.\"\n",
        "    end_time = time.time()\n",
        "    return {\"best_combination\": best_outfit_info, \"explanation\": explanation, \"best_score\": best_score, \"processing_time\": end_time - start_time}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ie42SukU5ew",
        "outputId": "869d060e-5369-4119-816e-151a030c1cf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting serve_final.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. 서버 실행 및 ngrok 터널 생성 ---\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "def run_app():\n",
        "  uvicorn.run(\"serve_final:app\", host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()\n",
        "print(\"\\n✅ FastAPI 서버가 백그라운드에서 실행을 시작했습니다...\")\n",
        "\n",
        "print(\"⏳ 서버가 모델을 로딩하고 준비될 때까지 대기 중입니다...\")\n",
        "start_time = time.time()\n",
        "server_ready = False\n",
        "while time.time() - start_time < 600:\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:8000/\", timeout=5)\n",
        "        if response.status_code == 404:\n",
        "            print(\"✅ 서버가 응답하기 시작했습니다!\")\n",
        "            server_ready = True\n",
        "            break\n",
        "    except requests.exceptions.ConnectionError: time.sleep(5); print(\"...\")\n",
        "if not server_ready:\n",
        "    print(\"❌ 10분이 지나도 서버가 준비되지 않았습니다. 런타임을 재시작하고 다시 시도해주세요.\")\n",
        "else:\n",
        "    NGROK_TOKEN = \"31HHkLEWGt90qDRoAWd6BqiGL9K_5fJsXN7LgijbtcAVwkwAS\" # 🚨\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    ngrok.kill()\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"\\n🎉 서버가 성공적으로 생성되었습니다. API 주소: {public_url}\")\n",
        "    print(\"이제 이 주소를 test_api.py에 넣고 로컬에서 테스트를 실행하세요.\")\n",
        "\n",
        "thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997,
          "referenced_widgets": [
            "33e94d12dd6b4e9ca8a1b7df296fc5a4",
            "318759094f844485b706f715aaa5652b",
            "594584672bec40d0ab6404c95fe3cbde",
            "380dce4cb001447ab17fb5cf5f98fabe",
            "f533b1bf0f4a499ab3431bfa1b662038",
            "c7cc48422fda49ddad1a1baf7a4db96a",
            "1ad3aa20c4204920b93bfd211cea51c8",
            "77a72adde19a46e38c017f91e9b9ba4b",
            "75746e8bc25d41dc8a20b948c8ff1a4c",
            "3a24d4fb92e64fbf8c0cbe37f0309eb5",
            "c160e78899a1432e9ef25d56b30a27e5"
          ]
        },
        "id": "SWXp4hfsVDaM",
        "outputId": "fbf268d9-8ce3-4448-ee19-6dfc49ecc4e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ FastAPI 서버가 백그라운드에서 실행을 시작했습니다...\n",
            "⏳ 서버가 모델을 로딩하고 준비될 때까지 대기 중입니다...\n",
            "...\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [24222]\n",
            "INFO:     Waiting for application startup.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33e94d12dd6b4e9ca8a1b7df296fc5a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n",
            "...\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n",
            "...\n",
            "INFO:     127.0.0.1:34878 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "✅ 서버가 응답하기 시작했습니다!\n",
            "\n",
            "🎉 서버가 성공적으로 생성되었습니다. API 주소: NgrokTunnel: \"https://39f17048bb40.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "이제 이 주소를 test_api.py에 넣고 로컬에서 테스트를 실행하세요.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-01T12:57:06+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     39.113.75.42:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2770823529.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"이제 이 주소를 test_api.py에 넣고 로컬에서 테스트를 실행하세요.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}