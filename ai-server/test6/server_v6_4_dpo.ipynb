{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxzBr-8UUqTt"
      },
      "outputs": [],
      "source": [
        "# --- 1. 필수 라이브러리 설치 ---\n",
        "!pip install -q -U transformers peft accelerate trl datasets huggingface_hub fastapi \"uvicorn[standard]\" pyngrok bitsandbytes \"pandas==2.2.2\" \"psycopg2-binary\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba6nuss7UyIt",
        "outputId": "4dd0396b-5c13-4930-e735-bf4f8d151ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 📂 파일들을 업로드합니다 ---\n",
            "'gemma-fashion-dpo-final-v3.zip'이(가) 이미 존재합니다.\n",
            "'styles.csv'이(가) 이미 존재합니다.\n"
          ]
        }
      ],
      "source": [
        "# --- 2. 파일 업로드 및 로그인 ---\n",
        "from google.colab import files\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "print(\"--- 📂 파일들을 업로드합니다 ---\")\n",
        "files_to_upload = ['gemma-fashion-dpo-final-v3.zip', 'styles.csv']\n",
        "for filename in files_to_upload:\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"\\n'{filename}'을 업로드해주세요.\")\n",
        "        files.upload()\n",
        "    else:\n",
        "        print(f\"'{filename}'이(가) 이미 존재합니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSLsuKKYU2BL",
        "outputId": "ccd3397b-1055-4ccf-95be-c405acdf873a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "모델 폴더 압축을 해제합니다...\n",
            "✅ 'adapter_config.json'의 정확한 경로를 찾았습니다: /content/content/gemma-fashion-dpo-final-v3\n"
          ]
        }
      ],
      "source": [
        "# --- 3. 모델 폴더 압축 해제 및 '자동 경로 탐지' ---\n",
        "print(\"\\n모델 폴더 압축을 해제합니다...\")\n",
        "!unzip -q -o gemma-fashion-dpo-final-v3.zip -d /content/\n",
        "\n",
        "ADAPTER_PATH_FOUND = \"\"\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if 'adapter_config.json' in files:\n",
        "        ADAPTER_PATH_FOUND = root\n",
        "        break\n",
        "\n",
        "if not ADAPTER_PATH_FOUND:\n",
        "    raise FileNotFoundError(\"압축 해제 후 'adapter_config.json'을 찾을 수 없습니다. Zip 파일을 확인해주세요.\")\n",
        "\n",
        "print(f\"✅ 'adapter_config.json'의 정확한 경로를 찾았습니다: {ADAPTER_PATH_FOUND}\")\n",
        "# ❗ 찾은 경로를 환경 변수에 저장합니다.\n",
        "os.environ['ADAPTER_PATH'] = ADAPTER_PATH_FOUND\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ie42SukU5ew",
        "outputId": "1fa47640-5fb5-4ca7-c22b-43093f68bbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting serve_final.py\n"
          ]
        }
      ],
      "source": [
        "#@title 3. API 서버 코드 작성 (serve_final.py) - 최종 폴백 시스템 적용\n",
        "\n",
        "%%writefile serve_final.py\n",
        "\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "import time\n",
        "import random\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "import uvicorn\n",
        "import logging\n",
        "\n",
        "# --- (기본 설정 및 전역 변수 선언은 이전과 동일) ---\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "app = FastAPI()\n",
        "model, tokenizer, styles_info, positive_token_id, negative_token_id = None, None, None, None, None\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_resources():\n",
        "    # ... (이전과 동일한 모델 로딩 로직)\n",
        "    global model, tokenizer, styles_info, positive_token_id, negative_token_id\n",
        "    logger.info(\"✅ 최종 DPO 모델 로딩을 시작합니다...\")\n",
        "    adapter_path = \"/content/content/gemma-fashion-dpo-final-v3\"\n",
        "    quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", quantization_config=quantization_config, device_map=\"auto\")\n",
        "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "    model.eval()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    positive_token_id = tokenizer.encode(\"긍정적\", add_special_tokens=False)[0]\n",
        "    negative_token_id = tokenizer.encode(\"부정적\", add_special_tokens=False)[0]\n",
        "    logger.info(\"✅ 모델 및 토크나이저 로딩 완료!\")\n",
        "    styles_df = pd.read_csv(\"styles.csv\", on_bad_lines='skip', dtype={'id': int}).set_index('id')\n",
        "    styles_info = styles_df.to_dict('index')\n",
        "    logger.info(\"✅ styles.csv 로드 완료!\")\n",
        "\n",
        "def get_item_description(item_id):\n",
        "    # ... (이전과 동일)\n",
        "    if item_id not in styles_info: return \"\"\n",
        "    info = styles_info[item_id]; season = info.get('season', 'All')\n",
        "    return f\"{info.get('baseColour', '')} {info.get('articleType', '')} ({season})\".strip()\n",
        "\n",
        "class ClosetItem(BaseModel):\n",
        "    id: int; gender: str; masterCategory: str; subCategory: str\n",
        "    articleType: str; baseColor: str; season: str; usage: str\n",
        "\n",
        "\n",
        "class OutfitRequest(BaseModel):\n",
        "    closet: List[int]; event: str; temperature: float; condition: str; gender: str\n",
        "\n",
        "@app.post(\"/recommend_outfit\")\n",
        "def recommend_outfit(req: OutfitRequest):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # --- 1단계: 개별 아이템 평가 (이전과 동일) ---\n",
        "    temp = req.temperature; event = req.event\n",
        "    if temp <= 10: suitable_seasons = ['Winter', 'Fall']\n",
        "    else: suitable_seasons = ['Summer', 'Spring', 'All Season']\n",
        "    target_usage = ['Casual', 'Smart Casual']\n",
        "    if event in [\"Business Meeting\", \"Formal Dinner\"]: target_usage = ['Formal', 'Smart Casual']\n",
        "    elif event in [\"Gym Workout\", \"Hiking\", \"Sports\"]: target_usage = ['Sports', 'Active']\n",
        "    filtered_closet_ids = [ id for id in req.closet if id in styles_info and (styles_info[id].get('season') in suitable_seasons or styles_info[id].get('season') == 'All Season') and (styles_info[id].get('usage') in target_usage) ]\n",
        "    if not filtered_closet_ids: return {\"error\": \"현재 상황에 맞는 아이템이 옷장에 없습니다.\"}\n",
        "    item_prompts = [f\"상황: {req.gender}, {req.temperature}°C, {req.condition}, {req.event}\\n옷: {get_item_description(item_id)}\\n결과:\" for item_id in filtered_closet_ids]\n",
        "    inputs = tokenizer(item_prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad(): outputs = model(**inputs)\n",
        "    sequence_lengths = inputs['attention_mask'].sum(dim=1) - 1\n",
        "    last_token_logits = outputs.logits[torch.arange(len(filtered_closet_ids)), sequence_lengths]\n",
        "    logits_for_scoring = last_token_logits[:, [negative_token_id, positive_token_id]]\n",
        "    probs = torch.softmax(logits_for_scoring, dim=-1)\n",
        "    item_scores = probs[:, 1].tolist()\n",
        "    scored_items = {filtered_closet_ids[i]: item_scores[i] for i in range(len(filtered_closet_ids))}\n",
        "\n",
        "    # --- 2단계: 최우수 후보 선정 및 조합 생성 ---\n",
        "    TOP_K_ITEMS_PER_PART = 3\n",
        "    classified_items = { 'Topwear': [], 'Bottomwear': [], 'Outerwear': [], 'Footwear': [], 'Full Body': [] }\n",
        "    outerwear_types = ['Jackets', 'Blazers', 'Waistcoat', 'Coat', 'Shrug', 'Cardigan', 'Nehru Jackets', 'Rain Jacket', 'Sweaters']\n",
        "    full_body_types = ['Dresses', 'Jumpsuit']\n",
        "    for item_id in filtered_closet_ids:\n",
        "        info = styles_info[item_id]; part = None\n",
        "        if info.get('articleType') in full_body_types: part = 'Full Body'\n",
        "        elif info.get('articleType') in outerwear_types: part = 'Outerwear'\n",
        "        elif info.get('subCategory') == 'Topwear': part = 'Topwear'\n",
        "        elif info.get('subCategory') == 'Bottomwear': part = 'Bottomwear'\n",
        "        elif info.get('masterCategory') == 'Footwear': part = 'Footwear'\n",
        "        if part: classified_items[part].append(item_id)\n",
        "\n",
        "    top_items_by_part = { part: sorted(items, key=lambda x: scored_items.get(x, 0), reverse=True)[:TOP_K_ITEMS_PER_PART] for part, items in classified_items.items() }\n",
        "\n",
        "    # --- ★ NEW: 지능형 폴백(Fallback) 로직 ---\n",
        "    def generate_combinations(items_pool):\n",
        "        \"\"\"주어진 아이템 풀로 조합을 생성하는 함수\"\"\"\n",
        "        base = list(product(items_pool.get('Topwear', []), items_pool.get('Bottomwear', []), items_pool.get('Footwear', [])))\n",
        "        outer = list(product(items_pool.get('Topwear', []), items_pool.get('Bottomwear', []), items_pool.get('Outerwear', []), items_pool.get('Footwear', [])))\n",
        "        full_body = list(product(items_pool.get('Full Body', []), items_pool.get('Footwear', [])))\n",
        "        return [c for c in base + outer + full_body if c]\n",
        "\n",
        "    # 1차 시도: 최상위 아이템으로 조합 생성\n",
        "    all_combinations = generate_combinations(top_items_by_part)\n",
        "\n",
        "    # 2차 시도: 1차 실패 시, 필터링 통과한 모든 아이템으로 재시도\n",
        "    if not all_combinations:\n",
        "        logger.warning(\"상위 아이템으로 조합 생성 실패. 필터링된 전체 아이템으로 재시도합니다.\")\n",
        "        all_combinations = generate_combinations(classified_items)\n",
        "\n",
        "    if not all_combinations:\n",
        "        return {\"error\": \"옷장의 아이템들로 유효한 조합을 만들 수 없습니다.\"}\n",
        "\n",
        "    # (이하 AI 최종 평가 및 결과 반환 로직은 이전과 동일)\n",
        "    prompts = [ f\"상황: {req.gender}, {req.temperature}°C, {req.condition}, {req.event}\\n옷: {', '.join([get_item_description(id) for id in combo])}\\n결과:\" for combo in all_combinations ]\n",
        "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad(): outputs = model(**inputs)\n",
        "    sequence_lengths = inputs['attention_mask'].sum(dim=1) - 1\n",
        "    last_token_logits = outputs.logits[torch.arange(len(all_combinations)), sequence_lengths]\n",
        "    logits_for_scoring = last_token_logits[:, [negative_token_id, positive_token_id]]\n",
        "    probs = torch.softmax(logits_for_scoring, dim=-1)\n",
        "    all_scores = probs[:, 1].tolist()\n",
        "    best_score_index = all_scores.index(max(all_scores))\n",
        "    best_score = all_scores[best_score_index]\n",
        "    best_combo = all_combinations[best_score_index]\n",
        "    best_combo_ids = [int(id_val) for id_val in best_combo if id_val is not None]\n",
        "    outfit_str = \", \".join([get_item_description(id) for id in best_combo_ids])\n",
        "    best_outfit_info = {\"description\": outfit_str, \"ids\": best_combo_ids}\n",
        "    explanation = f\"긍정적: {req.temperature}°C의 {req.condition} 날씨에 진행되는 {req.event}에 가장 잘 어울리는 스타일입니다.\"\n",
        "    end_time = time.time()\n",
        "    return {\"best_combination\": best_outfit_info, \"explanation\": explanation, \"best_score\": best_score, \"processing_time\": end_time - start_time}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929,
          "referenced_widgets": [
            "651e87aab2834d9097d77ecf58568064",
            "b086544b4eb64143ad75580662f80e05",
            "c050b9128636421da8eec3ce683f8b8c",
            "7536ab80828149d2a5be66dca850bf14",
            "1ce958cf02ca4d179b4223d55f7949fa",
            "ceb87a3596b54561bb1e6298ab32f3cb",
            "65de6acb19bc4a01b4ee6fb98eaff3f8",
            "a96cc2c533564abdabd4287a7298ea0c",
            "f8d00472d8aa40298a0127340bc3d95c",
            "d971e2f173c240f7b1c55d697e8dc856",
            "2ee30fc3dda94a009b6a119a12058014"
          ]
        },
        "id": "SWXp4hfsVDaM",
        "outputId": "8c06ec47-efab-4454-e204-c607f34e16d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ FastAPI 서버가 백그라운드에서 실행을 시작했습니다...\n",
            "⏳ 서버가 모델을 로딩하고 준비될 때까지 대기 중입니다...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [22481]\n",
            "INFO:     Waiting for application startup.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 'serve_final.py' 파일이 성공적으로 생성되었습니다.\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "651e87aab2834d9097d77ecf58568064"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n",
            "...\n",
            "...\n",
            "...\n",
            "...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n",
            "INFO:     127.0.0.1:42426 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "✅ 서버가 응답하기 시작했습니다!\n",
            "\n",
            "🎉 서버가 성공적으로 생성되었습니다. API 주소: NgrokTunnel: \"https://58fea4bf219d.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "이제 이 주소를 test_api.py에 넣고 로컬에서 테스트를 실행하세요.\n",
            "INFO:     27.0.238.70:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     27.0.238.70:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     61.42.109.11:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     61.42.109.11:0 - \"POST /recommend_outfit HTTP/1.1\" 200 OK\n",
            "INFO:     27.0.238.187:0 - \"GET / HTTP/1.1\" 404 Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-03T09:23:36+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-999249fc-668f-48d6-a600-f06930fdd77a acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-09-03T09:23:36+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8000-999249fc-668f-48d6-a600-f06930fdd77a err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2770823529.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"이제 이 주소를 test_api.py에 넣고 로컬에서 테스트를 실행하세요.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# --- 5. 서버 실행 및 ngrok 터널 생성 ---\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "def run_app():\n",
        "  uvicorn.run(\"serve_final:app\", host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()\n",
        "print(\"\\n✅ FastAPI 서버가 백그라운드에서 실행을 시작했습니다...\")\n",
        "\n",
        "print(\"⏳ 서버가 모델을 로딩하고 준비될 때까지 대기 중입니다...\")\n",
        "start_time = time.time()\n",
        "server_ready = False\n",
        "while time.time() - start_time < 600:\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:8000/\", timeout=5)\n",
        "        if response.status_code == 404:\n",
        "            print(\"✅ 서버가 응답하기 시작했습니다!\")\n",
        "            server_ready = True\n",
        "            break\n",
        "    except requests.exceptions.ConnectionError: time.sleep(5); print(\"...\")\n",
        "if not server_ready:\n",
        "    print(\"❌ 10분이 지나도 서버가 준비되지 않았습니다. 런타임을 재시작하고 다시 시도해주세요.\")\n",
        "else:\n",
        "    NGROK_TOKEN = \"31HHkLEWGt90qDRoAWd6BqiGL9K_5fJsXN7LgijbtcAVwkwAS\" # 🚨\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    ngrok.kill()\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"\\n🎉 서버가 성공적으로 생성되었습니다. API 주소: {public_url}\")\n",
        "    print(\"이제 이 주소를 test_api.py에 넣고 로컬에서 테스트를 실행하세요.\")\n",
        "\n",
        "thread.join()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "651e87aab2834d9097d77ecf58568064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b086544b4eb64143ad75580662f80e05",
              "IPY_MODEL_c050b9128636421da8eec3ce683f8b8c",
              "IPY_MODEL_7536ab80828149d2a5be66dca850bf14"
            ],
            "layout": "IPY_MODEL_1ce958cf02ca4d179b4223d55f7949fa"
          }
        },
        "b086544b4eb64143ad75580662f80e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceb87a3596b54561bb1e6298ab32f3cb",
            "placeholder": "​",
            "style": "IPY_MODEL_65de6acb19bc4a01b4ee6fb98eaff3f8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c050b9128636421da8eec3ce683f8b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a96cc2c533564abdabd4287a7298ea0c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8d00472d8aa40298a0127340bc3d95c",
            "value": 2
          }
        },
        "7536ab80828149d2a5be66dca850bf14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d971e2f173c240f7b1c55d697e8dc856",
            "placeholder": "​",
            "style": "IPY_MODEL_2ee30fc3dda94a009b6a119a12058014",
            "value": " 2/2 [00:21&lt;00:00,  9.05s/it]"
          }
        },
        "1ce958cf02ca4d179b4223d55f7949fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb87a3596b54561bb1e6298ab32f3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65de6acb19bc4a01b4ee6fb98eaff3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a96cc2c533564abdabd4287a7298ea0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d00472d8aa40298a0127340bc3d95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d971e2f173c240f7b1c55d697e8dc856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee30fc3dda94a009b6a119a12058014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}